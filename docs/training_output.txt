-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
V1.0: batch_size=512, epochs=50/50 训练时间4个小时
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
Epoch 1/50
2018-06-06 23:55:47.736378: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
104092/104092 [==============================] - 293s 3ms/step - loss: 1.3047 - acc: 0.5096 - val_loss: 1.2900 - val_acc: 0.5079
Epoch 2/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.2740 - acc: 0.5110 - val_loss: 1.2424 - val_acc: 0.5079
Epoch 3/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.2445 - acc: 0.5110 - val_loss: 1.2394 - val_acc: 0.5079
Epoch 4/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.2368 - acc: 0.5109 - val_loss: 1.2320 - val_acc: 0.5080
Epoch 5/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.2358 - acc: 0.5113 - val_loss: 1.2333 - val_acc: 0.5081
Epoch 6/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.2349 - acc: 0.5119 - val_loss: 1.2325 - val_acc: 0.5084
Epoch 7/50
104092/104092 [==============================] - 293s 3ms/step - loss: 1.2340 - acc: 0.5120 - val_loss: 1.2274 - val_acc: 0.5092
Epoch 8/50
104092/104092 [==============================] - 293s 3ms/step - loss: 1.2292 - acc: 0.5133 - val_loss: 1.2289 - val_acc: 0.5083
Epoch 9/50
104092/104092 [==============================] - 293s 3ms/step - loss: 1.2272 - acc: 0.5136 - val_loss: 1.2258 - val_acc: 0.5090
Epoch 10/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.2547 - acc: 0.5108 - val_loss: 1.2396 - val_acc: 0.5079

Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.
Epoch 11/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.2347 - acc: 0.5107 - val_loss: 1.2290 - val_acc: 0.5086
Epoch 12/50
104092/104092 [==============================] - 293s 3ms/step - loss: 1.2266 - acc: 0.5114 - val_loss: 1.2291 - val_acc: 0.5082
Epoch 13/50
104092/104092 [==============================] - 293s 3ms/step - loss: 1.2197 - acc: 0.5122 - val_loss: 1.2167 - val_acc: 0.5094
Epoch 14/50
104092/104092 [==============================] - 293s 3ms/step - loss: 1.2115 - acc: 0.5144 - val_loss: 1.2036 - val_acc: 0.5132
Epoch 15/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.2050 - acc: 0.5156 - val_loss: 1.1996 - val_acc: 0.5145
Epoch 16/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.2015 - acc: 0.5169 - val_loss: 1.1950 - val_acc: 0.5166

...

Epoch 41/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.0754 - acc: 0.5662 - val_loss: 1.0685 - val_acc: 0.5682
Epoch 42/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.0717 - acc: 0.5682 - val_loss: 1.0705 - val_acc: 0.5679
Epoch 43/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.0677 - acc: 0.5689 - val_loss: 1.0697 - val_acc: 0.5681
Epoch 44/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.0637 - acc: 0.5702 - val_loss: 1.0628 - val_acc: 0.5707
Epoch 45/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.0608 - acc: 0.5723 - val_loss: 1.0703 - val_acc: 0.5667
Epoch 46/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.0586 - acc: 0.5727 - val_loss: 1.0594 - val_acc: 0.5729
Epoch 47/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.0566 - acc: 0.5734 - val_loss: 1.0664 - val_acc: 0.5688
Epoch 48/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.0558 - acc: 0.5729 - val_loss: 1.0618 - val_acc: 0.5690
Epoch 49/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.0519 - acc: 0.5751 - val_loss: 1.0559 - val_acc: 0.5721

Epoch 00049: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.
Epoch 50/50
104092/104092 [==============================] - 292s 3ms/step - loss: 1.0407 - acc: 0.5794 - val_loss: 1.0468 - val_acc: 0.5763

-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
V2.0: batch_size=1024, epochs=295/300, 训练时间22小时，训练速度太慢
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
Epoch 1/300
104092/104092 [==============================] - 265s 3ms/step - loss: 1.3147 - acc: 0.5075 - val_loss: 1.2838 - val_acc: 0.5079
Epoch 2/300
104092/104092 [==============================] - 265s 3ms/step - loss: 1.2849 - acc: 0.5110 - val_loss: 1.2800 - val_acc: 0.5079
Epoch 3/300
104092/104092 [==============================] - 265s 3ms/step - loss: 1.2774 - acc: 0.5110 - val_loss: 1.2655 - val_acc: 0.5079
Epoch 4/300
104092/104092 [==============================] - 266s 3ms/step - loss: 1.2521 - acc: 0.5110 - val_loss: 1.2470 - val_acc: 0.5079
Epoch 5/300
104092/104092 [==============================] - 265s 3ms/step - loss: 1.2473 - acc: 0.5110 - val_loss: 1.2391 - val_acc: 0.5079
...
Epoch 286/300
104092/104092 [==============================] - 267s 3ms/step - loss: 1.1139 - acc: 0.5513 - val_loss: 1.1087 - val_acc: 0.5531
Epoch 287/300
104092/104092 [==============================] - 267s 3ms/step - loss: 1.1127 - acc: 0.5520 - val_loss: 1.1094 - val_acc: 0.5527
Epoch 288/300
104092/104092 [==============================] - 268s 3ms/step - loss: 1.1135 - acc: 0.5523 - val_loss: 1.1089 - val_acc: 0.5530
Epoch 289/300
104092/104092 [==============================] - 267s 3ms/step - loss: 1.1129 - acc: 0.5521 - val_loss: 1.1096 - val_acc: 0.5527
Epoch 290/300
104092/104092 [==============================] - 267s 3ms/step - loss: 1.1129 - acc: 0.5515 - val_loss: 1.1089 - val_acc: 0.5535
Epoch 291/300
104092/104092 [==============================] - 266s 3ms/step - loss: 1.1131 - acc: 0.5524 - val_loss: 1.1087 - val_acc: 0.5536
Epoch 292/300
104092/104092 [==============================] - 266s 3ms/step - loss: 1.1130 - acc: 0.5516 - val_loss: 1.1086 - val_acc: 0.5530
Epoch 293/300
104092/104092 [==============================] - 267s 3ms/step - loss: 1.1124 - acc: 0.5529 - val_loss: 1.1087 - val_acc: 0.5522
Epoch 294/300
104092/104092 [==============================] - 267s 3ms/step - loss: 1.1133 - acc: 0.5519 - val_loss: 1.1093 - val_acc: 0.5526
Epoch 295/300
104092/104092 [==============================] - 267s 3ms/step - loss: 1.1133 - acc: 0.5507 - val_loss: 1.1088 - val_acc: 0.5528
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
batch_size=512, epochs=75/100  训练时间5小时10分钟
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
Epoch 1/100
2018-06-08 09:42:20.410424: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA
71040/71040 [==============================] - 200s 3ms/step - loss: 1.3598 - acc: 0.4689 - val_loss: 1.3465 - val_acc: 0.4672
Epoch 2/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.3392 - acc: 0.4708 - val_loss: 1.3415 - val_acc: 0.4672
Epoch 3/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.3343 - acc: 0.4708 - val_loss: 1.3327 - val_acc: 0.4672
Epoch 4/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.3155 - acc: 0.4708 - val_loss: 1.3261 - val_acc: 0.4672
Epoch 5/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.3131 - acc: 0.4708 - val_loss: 1.3177 - val_acc: 0.4672
Epoch 6/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.3058 - acc: 0.4708 - val_loss: 1.3130 - val_acc: 0.4672
Epoch 7/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.3014 - acc: 0.4712 - val_loss: 1.3085 - val_acc: 0.4698
Epoch 8/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.3005 - acc: 0.4707 - val_loss: 1.3061 - val_acc: 0.4681
Epoch 9/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.2983 - acc: 0.4713 - val_loss: 1.3016 - val_acc: 0.4702
Epoch 10/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.2955 - acc: 0.4726 - val_loss: 1.3013 - val_acc: 0.4707
...
Epoch 71/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.0824 - acc: 0.5479 - val_loss: 1.1597 - val_acc: 0.5199
Epoch 72/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.0801 - acc: 0.5488 - val_loss: 1.1620 - val_acc: 0.5202
Epoch 73/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.0781 - acc: 0.5480 - val_loss: 1.1582 - val_acc: 0.5188
Epoch 74/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.0758 - acc: 0.5485 - val_loss: 1.1668 - val_acc: 0.5156
Epoch 75/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.0739 - acc: 0.5496 - val_loss: 1.1647 - val_acc: 0.5170
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
batch_size=128, epochs=69/100 训练时间5小时16分钟
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
Epoch 1/100
71040/71040 [==============================] - 275s 4ms/step - loss: 1.3486 - acc: 0.4697 - val_loss: 1.3472 - val_acc: 0.4672
Epoch 2/100
71040/71040 [==============================] - 275s 4ms/step - loss: 1.3400 - acc: 0.4708 - val_loss: 1.3470 - val_acc: 0.4672
Epoch 3/100
71040/71040 [==============================] - 274s 4ms/step - loss: 1.3397 - acc: 0.4708 - val_loss: 1.3464 - val_acc: 0.4672
Epoch 4/100
71040/71040 [==============================] - 275s 4ms/step - loss: 1.3386 - acc: 0.4708 - val_loss: 1.3461 - val_acc: 0.4672
Epoch 5/100
71040/71040 [==============================] - 274s 4ms/step - loss: 1.3385 - acc: 0.4708 - val_loss: 1.3456 - val_acc: 0.4672
Epoch 6/100
71040/71040 [==============================] - 274s 4ms/step - loss: 1.3171 - acc: 0.4708 - val_loss: 1.3123 - val_acc: 0.4672
Epoch 7/100
71040/71040 [==============================] - 274s 4ms/step - loss: 1.3002 - acc: 0.4707 - val_loss: 1.3077 - val_acc: 0.4673
Epoch 8/100
71040/71040 [==============================] - 274s 4ms/step - loss: 1.2930 - acc: 0.4704 - val_loss: 1.2983 - val_acc: 0.4672
Epoch 9/100
71040/71040 [==============================] - 274s 4ms/step - loss: 1.2903 - acc: 0.4707 - val_loss: 1.3119 - val_acc: 0.4680
Epoch 10/100
71040/71040 [==============================] - 274s 4ms/step - loss: 1.2851 - acc: 0.4708 - val_loss: 1.3010 - val_acc: 0.4672
...
Epoch 59/100
71040/71040 [==============================] - 274s 4ms/step - loss: 1.0698 - acc: 0.5519 - val_loss: 1.1497 - val_acc: 0.5235
Epoch 60/100
71040/71040 [==============================] - 274s 4ms/step - loss: 1.0674 - acc: 0.5524 - val_loss: 1.1595 - val_acc: 0.5185
Epoch 61/100
71040/71040 [==============================] - 274s 4ms/step - loss: 1.0656 - acc: 0.5519 - val_loss: 1.1575 - val_acc: 0.5190
Epoch 62/100
71040/71040 [==============================] - 274s 4ms/step - loss: 1.0614 - acc: 0.5535 - val_loss: 1.1533 - val_acc: 0.5232
Epoch 63/100
71040/71040 [==============================] - 274s 4ms/step - loss: 1.0592 - acc: 0.5560 - val_loss: 1.1543 - val_acc: 0.5198
Epoch 64/100
71040/71040 [==============================] - 274s 4ms/step - loss: 1.0548 - acc: 0.5550 - val_loss: 1.1619 - val_acc: 0.5128

Epoch 00064: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.
Epoch 65/100
71040/71040 [==============================] - 274s 4ms/step - loss: 1.0485 - acc: 0.5583 - val_loss: 1.1525 - val_acc: 0.5203
Epoch 66/100
71040/71040 [==============================] - 274s 4ms/step - loss: 1.0450 - acc: 0.5620 - val_loss: 1.1657 - val_acc: 0.5196
Epoch 67/100
71040/71040 [==============================] - 274s 4ms/step - loss: 1.0419 - acc: 0.5604 - val_loss: 1.1545 - val_acc: 0.5198
Epoch 68/100
71040/71040 [==============================] - 274s 4ms/step - loss: 1.0383 - acc: 0.5619 - val_loss: 1.1577 - val_acc: 0.5184
Epoch 69/100
71040/71040 [==============================] - 274s 4ms/step - loss: 1.0354 - acc: 0.5640 - val_loss: 1.1632 - val_acc: 0.5187

-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
batch_size=64, epochs=74/100  训练时间7小时35分钟(后面训练集和验证集的loss都在上升？为什么会这样？)
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
71040/71040 [==============================] - 369s 5ms/step - loss: 1.3435 - acc: 0.4705 - val_loss: 1.3459 - val_acc: 0.4672
Epoch 2/100
71040/71040 [==============================] - 368s 5ms/step - loss: 1.3401 - acc: 0.4708 - val_loss: 1.3457 - val_acc: 0.4672
Epoch 3/100
71040/71040 [==============================] - 368s 5ms/step - loss: 1.3380 - acc: 0.4708 - val_loss: 1.3454 - val_acc: 0.4672
Epoch 4/100
71040/71040 [==============================] - 368s 5ms/step - loss: 1.3408 - acc: 0.4708 - val_loss: 1.3458 - val_acc: 0.4672
Epoch 5/100
71040/71040 [==============================] - 369s 5ms/step - loss: 1.3386 - acc: 0.4708 - val_loss: 1.3440 - val_acc: 0.4672
Epoch 6/100
71040/71040 [==============================] - 368s 5ms/step - loss: 1.3322 - acc: 0.4708 - val_loss: 1.3303 - val_acc: 0.4672
Epoch 7/100
71040/71040 [==============================] - 368s 5ms/step - loss: 1.3376 - acc: 0.4708 - val_loss: 1.3419 - val_acc: 0.4672
Epoch 8/100
71040/71040 [==============================] - 368s 5ms/step - loss: 1.3355 - acc: 0.4708 - val_loss: 1.3434 - val_acc: 0.4672
Epoch 9/100
71040/71040 [==============================] - 369s 5ms/step - loss: 1.3352 - acc: 0.4708 - val_loss: 1.3427 - val_acc: 0.4672
Epoch 10/100
71040/71040 [==============================] - 368s 5ms/step - loss: 1.3347 - acc: 0.4708 - val_loss: 1.3420 - val_acc: 0.4672
...

Epoch 65/100
71040/71040 [==============================] - 369s 5ms/step - loss: 1.0697 - acc: 0.5519 - val_loss: 1.1265 - val_acc: 0.5312
Epoch 66/100
71040/71040 [==============================] - 369s 5ms/step - loss: 1.0654 - acc: 0.5520 - val_loss: 1.1354 - val_acc: 0.5232
Epoch 67/100
71040/71040 [==============================] - 369s 5ms/step - loss: 1.0635 - acc: 0.5550 - val_loss: 1.1213 - val_acc: 0.5317
Epoch 68/100
71040/71040 [==============================] - 368s 5ms/step - loss: 1.1481 - acc: 0.5268 - val_loss: 1.3241 - val_acc: 0.4671
Epoch 69/100
71040/71040 [==============================] - 369s 5ms/step - loss: 1.3103 - acc: 0.4682 - val_loss: 1.2908 - val_acc: 0.4675

Epoch 00069: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.
Epoch 70/100
71040/71040 [==============================] - 369s 5ms/step - loss: 1.2890 - acc: 0.4721 - val_loss: 1.2796 - val_acc: 0.4723
Epoch 71/100
71040/71040 [==============================] - 368s 5ms/step - loss: 1.2810 - acc: 0.4715 - val_loss: 1.2718 - val_acc: 0.4702
Epoch 72/100
71040/71040 [==============================] - 369s 5ms/step - loss: 1.2718 - acc: 0.4742 - val_loss: 1.2661 - val_acc: 0.4765
Epoch 73/100
71040/71040 [==============================] - 368s 5ms/step - loss: 1.2643 - acc: 0.4767 - val_loss: 1.2596 - val_acc: 0.4770
Epoch 74/100
71040/71040 [==============================] - 368s 5ms/step - loss: 1.2616 - acc: 0.4751 - val_loss: 1.2549 - val_acc: 0.4803

-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
batch_size=512, epochs=88/100  训练时间7小时35分钟
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
Epoch 1/100
2018-06-09 10:07:34.521397: I tensorflow/core/platform/cpu_feature_guard.cc:140] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2
FMA
71040/71040 [==============================] - 200s 3ms/step - loss: 1.3570 - acc: 0.4688 - val_loss: 1.3453 - val_acc: 0.4672
Epoch 2/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.3468 - acc: 0.4707 - val_loss: 1.3453 - val_acc: 0.4672
Epoch 3/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.3373 - acc: 0.4708 - val_loss: 1.3421 - val_acc: 0.4672
Epoch 4/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.3395 - acc: 0.4708 - val_loss: 1.3432 - val_acc: 0.4672
Epoch 5/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.3350 - acc: 0.4708 - val_loss: 1.3389 - val_acc: 0.4672
Epoch 6/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.3240 - acc: 0.4708 - val_loss: 1.3481 - val_acc: 0.4672
Epoch 7/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.3121 - acc: 0.4708 - val_loss: 1.3208 - val_acc: 0.4672
Epoch 8/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.3060 - acc: 0.4708 - val_loss: 1.3253 - val_acc: 0.4672
Epoch 9/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.3041 - acc: 0.4711 - val_loss: 1.3115 - val_acc: 0.4673
Epoch 10/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.2994 - acc: 0.4716 - val_loss: 1.3098 - val_acc: 0.4688
Epoch 11/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.3022 - acc: 0.4710 - val_loss: 1.3083 - val_acc: 0.4683
Epoch 12/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.2985 - acc: 0.4716 - val_loss: 1.3029 - val_acc: 0.4685
Epoch 13/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.2985 - acc: 0.4713 - val_loss: 1.3118 - val_acc: 0.4673
...
Epoch 00076: ReduceLROnPlateau reducing learning rate to 0.0005120000336319208.
Epoch 77/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.0944 - acc: 0.5438 - val_loss: 1.1569 - val_acc: 0.5172
Epoch 78/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.0939 - acc: 0.5432 - val_loss: 1.1521 - val_acc: 0.5204
Epoch 79/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.0909 - acc: 0.5454 - val_loss: 1.1593 - val_acc: 0.5219
Epoch 80/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.0907 - acc: 0.5457 - val_loss: 1.1557 - val_acc: 0.5206
Epoch 81/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.0891 - acc: 0.5438 - val_loss: 1.1546 - val_acc: 0.5185
Epoch 82/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.0841 - acc: 0.5489 - val_loss: 1.1565 - val_acc: 0.5203
Epoch 83/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.0830 - acc: 0.5474 - val_loss: 1.1553 - val_acc: 0.5218

Epoch 00083: ReduceLROnPlateau reducing learning rate to 0.00040960004553198815.
Epoch 84/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.0780 - acc: 0.5497 - val_loss: 1.1553 - val_acc: 0.5186
Epoch 85/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.0739 - acc: 0.5510 - val_loss: 1.1537 - val_acc: 0.5210
Epoch 86/100
71040/71040 [==============================] - 200s 3ms/step - loss: 1.0736 - acc: 0.5531 - val_loss: 1.1560 - val_acc: 0.5172
Epoch 87/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.0737 - acc: 0.5518 - val_loss: 1.1562 - val_acc: 0.5215
Epoch 88/100
71040/71040 [==============================] - 199s 3ms/step - loss: 1.0704 - acc: 0.5513 - val_loss: 1.1560 - val_acc: 0.5174

-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
batch_size=256, epochs=16/100  后面训练集和验证集的acc一直不变？为什么会这样？
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
Epoch 1/10
71040/71040 [==============================] - 232s 3ms/step - loss: 1.3511 - acc: 0.4697 - val_loss: 1.3450 - val_acc: 0.4672
Epoch 2/100
71040/71040 [==============================] - 231s 3ms/step - loss: 1.3522 - acc: 0.4684 - val_loss: 1.3454 - val_acc: 0.4672
Epoch 3/100
71040/71040 [==============================] - 231s 3ms/step - loss: 1.3391 - acc: 0.4708 - val_loss: 1.3454 - val_acc: 0.4672
Epoch 4/100
71040/71040 [==============================] - 231s 3ms/step - loss: 1.3369 - acc: 0.4708 - val_loss: 1.3437 - val_acc: 0.4672
Epoch 5/100
71040/71040 [==============================] - 231s 3ms/step - loss: 1.3364 - acc: 0.4708 - val_loss: 1.3449 - val_acc: 0.4672
Epoch 6/100
71040/71040 [==============================] - 231s 3ms/step - loss: 1.3360 - acc: 0.4708 - val_loss: 1.3433 - val_acc: 0.4672
Epoch 7/100
71040/71040 [==============================] - 231s 3ms/step - loss: 1.3360 - acc: 0.4708 - val_loss: 1.3450 - val_acc: 0.4672
Epoch 8/100
71040/71040 [==============================] - 231s 3ms/step - loss: 1.3356 - acc: 0.4708 - val_loss: 1.3441 - val_acc: 0.4672
Epoch 9/100
71040/71040 [==============================] - 231s 3ms/step - loss: 1.3353 - acc: 0.4708 - val_loss: 1.3436 - val_acc: 0.4672
Epoch 10/100
71040/71040 [==============================] - 231s 3ms/step - loss: 1.3354 - acc: 0.4708 - val_loss: 1.3434 - val_acc: 0.4672
Epoch 11/100
71040/71040 [==============================] - 231s 3ms/step - loss: 1.3348 - acc: 0.4708 - val_loss: 1.3437 - val_acc: 0.4672

Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.
Epoch 12/100
71040/71040 [==============================] - 231s 3ms/step - loss: 1.3352 - acc: 0.4708 - val_loss: 1.3435 - val_acc: 0.4672
Epoch 13/100
71040/71040 [==============================] - 231s 3ms/step - loss: 1.3349 - acc: 0.4708 - val_loss: 1.3435 - val_acc: 0.4672
Epoch 14/100
71040/71040 [==============================] - 231s 3ms/step - loss: 1.3352 - acc: 0.4708 - val_loss: 1.3438 - val_acc: 0.4672
Epoch 15/100
71040/71040 [==============================] - 231s 3ms/step - loss: 1.3341 - acc: 0.4708 - val_loss: 1.3434 - val_acc: 0.4672
Epoch 16/100
71040/71040 [==============================] - 231s 3ms/step - loss: 1.3340 - acc: 0.4708 - val_loss: 1.3448 - val_acc: 0.4672

-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
batch_size=32, epochs=50/100  训练时间8小时
-------------------------------------------------------------------------------------------
-------------------------------------------------------------------------------------------
Epoch 1/100
71040/71040 [==============================] - 575s 8ms/step - loss: 1.3446 - acc: 0.4706 - val_loss: 1.3475 - val_acc: 0.4672
Epoch 2/100
71040/71040 [==============================] - 575s 8ms/step - loss: 1.3394 - acc: 0.4708 - val_loss: 1.3462 - val_acc: 0.4672
Epoch 3/100
71040/71040 [==============================] - 576s 8ms/step - loss: 1.3235 - acc: 0.4708 - val_loss: 1.3172 - val_acc: 0.4672
Epoch 4/100
71040/71040 [==============================] - 575s 8ms/step - loss: 1.3102 - acc: 0.4704 - val_loss: 1.3456 - val_acc: 0.4672
Epoch 5/100
71040/71040 [==============================] - 575s 8ms/step - loss: 1.3389 - acc: 0.4708 - val_loss: 1.3407 - val_acc: 0.4672
Epoch 6/100
71040/71040 [==============================] - 575s 8ms/step - loss: 1.3244 - acc: 0.4708 - val_loss: 1.2942 - val_acc: 0.4672
Epoch 7/100
71040/71040 [==============================] - 575s 8ms/step - loss: 1.3056 - acc: 0.4710 - val_loss: 1.2914 - val_acc: 0.4672
Epoch 8/100
71040/71040 [==============================] - 575s 8ms/step - loss: 1.2814 - acc: 0.4721 - val_loss: 1.2734 - val_acc: 0.4727
Epoch 9/100
71040/71040 [==============================] - 575s 8ms/step - loss: 1.2697 - acc: 0.4755 - val_loss: 1.2740 - val_acc: 0.4769
Epoch 10/100
71040/71040 [==============================] - 575s 8ms/step - loss: 1.2613 - acc: 0.4781 - val_loss: 1.2621 - val_acc: 0.4763
...
Epoch 00038: ReduceLROnPlateau reducing learning rate to 0.000800000037997961.
Epoch 39/100
71040/71040 [==============================] - 577s 8ms/step - loss: 1.0734 - acc: 0.5506 - val_loss: 1.1286 - val_acc: 0.5285
Epoch 40/100
71040/71040 [==============================] - 577s 8ms/step - loss: 1.0689 - acc: 0.5511 - val_loss: 1.1262 - val_acc: 0.5265
Epoch 41/100
71040/71040 [==============================] - 577s 8ms/step - loss: 1.0620 - acc: 0.5528 - val_loss: 1.1343 - val_acc: 0.5242
Epoch 42/100
71040/71040 [==============================] - 577s 8ms/step - loss: 1.0624 - acc: 0.5530 - val_loss: 1.1346 - val_acc: 0.5242
Epoch 43/100
71040/71040 [==============================] - 577s 8ms/step - loss: 1.0581 - acc: 0.5550 - val_loss: 1.1354 - val_acc: 0.5245
Epoch 44/100
71040/71040 [==============================] - 577s 8ms/step - loss: 1.0528 - acc: 0.5591 - val_loss: 1.1314 - val_acc: 0.5282
Epoch 45/100
71040/71040 [==============================] - 577s 8ms/step - loss: 1.0503 - acc: 0.5567 - val_loss: 1.1278 - val_acc: 0.5275

Epoch 00045: ReduceLROnPlateau reducing learning rate to 0.0006400000303983689.
Epoch 46/100
71040/71040 [==============================] - 577s 8ms/step - loss: 1.0421 - acc: 0.5598 - val_loss: 1.1334 - val_acc: 0.5229
Epoch 47/100
71040/71040 [==============================] - 577s 8ms/step - loss: 1.0360 - acc: 0.5634 - val_loss: 1.1326 - val_acc: 0.5242
Epoch 48/100
71040/71040 [==============================] - 577s 8ms/step - loss: 1.0351 - acc: 0.5643 - val_loss: 1.1376 - val_acc: 0.5283
Epoch 49/100
71040/71040 [==============================] - 577s 8ms/step - loss: 1.0316 - acc: 0.5648 - val_loss: 1.1324 - val_acc: 0.5267
Epoch 50/100
71040/71040 [==============================] - 578s 8ms/step - loss: 1.0272 - acc: 0.5645 - val_loss: 1.1275 - val_acc: 0.5287

